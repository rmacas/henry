{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956fff84-b9f4-46f2-a69a-fa0cb528cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.fft import irfft\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0cd5d72-acf5-4691-9710-25479c6e1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(width: int, latent_dim : int, act_fn : object, encoder = True):\n",
    "    sizes = []\n",
    "    size = width\n",
    "    while size > 30:\n",
    "        sizes.append(int(size))\n",
    "        size = size / 2\n",
    "    sizes.append(latent_dim)\n",
    "\n",
    "    if encoder==False:\n",
    "        sizes = sizes[::-1]\n",
    "    layers = []\n",
    "    for layer_idx in range(len(sizes) - 1):\n",
    "        layers.append(nn.Linear(sizes[layer_idx], sizes[layer_idx+1]))\n",
    "        layers.append(act_fn())\n",
    "    layers.pop()\n",
    "\n",
    "    return layers\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, width: int, latent_dim: int, act_fn: object = nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(*get_layers(width, latent_dim, act_fn))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, width: int, latent_dim: int, act_fn: object = nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(*get_layers(width, latent_dim, act_fn, encoder=False))\n",
    "                                 \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0267c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        width: int,\n",
    "        latent_dim: int,\n",
    "        lr: float,\n",
    "        encoder_class: object = Encoder,\n",
    "        decoder_class: object = Decoder,\n",
    "    ):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "        self.width = width\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = encoder_class(width, latent_dim)\n",
    "        self.decoder = decoder_class(width, latent_dim)\n",
    "        self.val_loss = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "\n",
    "    def _get_reconstruction_loss(self, x):\n",
    "        x_hat = self.forward(x)\n",
    "        loss = F.mse_loss(x, x_hat)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.val_loss.append(loss)\n",
    "        self.log(\"val_loss\", loss, sync_dist=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.val_loss).mean()\n",
    "        self.log(\"val_loss\", avg_loss, sync_dist=True)\n",
    "        self.val_loss.clear()\n",
    "\n",
    "    def _test_plot(self, noisy:torch.Tensor, denoised:torch.Tensor, idx:int,\n",
    "                   loss:float):\n",
    "        noisy = noisy.cpu().numpy()\n",
    "        denoised = denoised.cpu().numpy()\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(noisy[idx,:], label='Noisy')\n",
    "        plt.plot(denoised[idx,:], label='Denoised')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xlim([0, self.width-1])\n",
    "        plt.ylabel('Normalized amplitude')\n",
    "        plt.xlabel('index')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(noisy[idx,:] - denoised[idx,:], label='Residual')\n",
    "        plt.legend()\n",
    "        plt.xlim([0, self.width-1])\n",
    "        plt.xlabel('index')\n",
    "        plt.suptitle(f'Loss: {loss:.7f}')\n",
    "        plt.savefig(f'reports/figures/{self.width}_{self.latent_dim}_{idx}.png', dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        x_hat = self.forward(batch)\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        rand = np.random.random(10)*batch.size(dim=0)  # indexes for plotting\n",
    "        for rand_no in rand:\n",
    "            self._test_plot(batch, x_hat, int(rand_no), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetData():\n",
    "    def __init__(\n",
    "        self,\n",
    "        width: int = 128\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.width = width\n",
    "    \n",
    "    def _gen_blip(self, fs:int, flow:int, fhigh:int, dt_shift:float):\n",
    "        freqs = np.arange(1 + fs//2)\n",
    "        spec = np.zeros(len(freqs))\n",
    "        logf = np.log(freqs[flow:fhigh])\n",
    "        spec1 = (logf-logf[0])*(logf[-1]-logf)\n",
    "        spec[flow:fhigh] = spec1/np.max(spec1)\n",
    "        spec_shifted = np.exp(-1j*freqs*2*np.pi*dt_shift)*spec\n",
    "        blip = np.roll(irfft(spec_shifted), fs//2)\n",
    "        return blip / np.max(blip)\n",
    "\n",
    "    def fake_blips(self, fs: int = 512):\n",
    "        dt_shifts = np.random.normal(0, 5, 50) / 1000  # in ms\n",
    "        f_lows = np.linspace(15, 35, 21, dtype=int)\n",
    "        f_highs = np.linspace(190, 230, 41, dtype=int)\n",
    "\n",
    "        blips = []\n",
    "        for dt_shift in dt_shifts:\n",
    "            for f_low in f_lows:\n",
    "                for f_high in f_highs:\n",
    "                    blip = self._gen_blip(fs, f_low, f_high, dt_shift)\n",
    "                    blips.append(blip)\n",
    "        blips = np.array(blips)\n",
    "        blips = blips[:, fs//2-self.width//2:fs//2+self.width//2]\n",
    "        blips = np.array(blips).astype('float32')\n",
    "        return blips\n",
    "\n",
    "    def shift_blips(self, dset : object = np.array): \n",
    "        shift_idxs = range(-5, 6)\n",
    "        shifted_blips = []\n",
    "        for idx in shift_idxs:\n",
    "            shifted_blips.append(np.roll(dset, idx, axis=1))\n",
    "        shifted_blips = np.array(shifted_blips)\n",
    "        shifted_blips = np.vstack(shifted_blips)\n",
    "        return shifted_blips\n",
    "\n",
    "    def real_blips(self, ddir : object = Path('data/external')):\n",
    "        files = ddir.glob('*.npy')\n",
    "        blips = []\n",
    "        for blip in files:\n",
    "            blip_data = np.load(blip)[:,1]\n",
    "            blips.append(blip_data)\n",
    "        blips = np.array(blips)\n",
    "        length = len(blips.T)\n",
    "        blips = blips[:, length//2-self.width//2:length//2+self.width//2]\n",
    "        blips = blips.astype('float32')\n",
    "        return blips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d4d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlitchDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: str = 'real',\n",
    "        batch_size: int = 100,\n",
    "        width: int = 128\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.width = width\n",
    "        self.prepare_data_per_node = False\n",
    "\n",
    "    def prepare_data(self):\n",
    "        gd = GetData(self.width)\n",
    "        if self.data == 'real':\n",
    "            self.glitch = F.normalize(torch.from_numpy(gd.real_blips()))\n",
    "        elif self.data == 'fake':\n",
    "            self.glitch = F.normalize(torch.from_numpy(gd.fake_blips()))\n",
    "        else:\n",
    "            raise SystemExit(\"Works only with 'real' and 'fake' data\")\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.glitch_train, self.glitch_val, self.glitch_test = torch.utils.data.random_split(self.glitch, [0.89, 0.1, 0.01], generator=torch.manual_seed(0))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.data == 'real':\n",
    "            # generate more glitches for training by shifting them\n",
    "            gd = GetData(self.width)\n",
    "            return DataLoader(gd.shift_blips(self.glitch_train), batch_size=self.batch_size, num_workers=4)\n",
    "        else:\n",
    "            return DataLoader(self.glitch_train, batch_size=self.batch_size, num_workers=4)\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.glitch_val, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.glitch_test, batch_size=len(self.glitch_test), num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb31aa86-d0f4-4de1-b1ef-e9f1a641a9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m dm \u001b[38;5;241m=\u001b[39m GlitchDataModule(data\u001b[38;5;241m=\u001b[39mdata, width\u001b[38;5;241m=\u001b[39mwidth)\n\u001b[1;32m      9\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39mepochs, accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_checkpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample.ckpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/bin/miniconda3/envs/henry/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bin/miniconda3/envs/henry/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/bin/miniconda3/envs/henry/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/bin/miniconda3/envs/henry/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:941\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m    940\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: preparing data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 941\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_connector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;66;03m# SET UP THE TRAINER\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    946\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: setting up strategy environment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/bin/miniconda3/envs/henry/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:94\u001b[0m, in \u001b[0;36m_DataConnector.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m     dm_prepare_data_per_node \u001b[38;5;241m=\u001b[39m datamodule\u001b[38;5;241m.\u001b[39mprepare_data_per_node\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dm_prepare_data_per_node \u001b[38;5;129;01mand\u001b[39;00m local_rank_zero) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m dm_prepare_data_per_node \u001b[38;5;129;01mand\u001b[39;00m global_rank_zero):\n\u001b[0;32m---> 94\u001b[0m         \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_datamodule_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprepare_data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# handle lightning module prepare data:\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# check for prepare_data_per_node before calling lightning_module.prepare_data\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/bin/miniconda3/envs/henry/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:179\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningDataModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mdatamodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m, in \u001b[0;36mGlitchDataModule.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m gd \u001b[38;5;241m=\u001b[39m GetData(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglitch \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal_blips\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfake\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglitch \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(gd\u001b[38;5;241m.\u001b[39mfake_blips()))\n",
      "Cell \u001b[0;32mIn[4], line 52\u001b[0m, in \u001b[0;36mGetData.real_blips\u001b[0;34m(self, ddir)\u001b[0m\n\u001b[1;32m     50\u001b[0m blips \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(blips)\n\u001b[1;32m     51\u001b[0m length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(blips\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m---> 52\u001b[0m blips \u001b[38;5;241m=\u001b[39m \u001b[43mblips\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m blips \u001b[38;5;241m=\u001b[39m blips\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m blips\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "data = 'real'\n",
    "width = 128\n",
    "latent_dim = 5\n",
    "lr = 1e-3\n",
    "epochs = 2\n",
    "ae = AutoEncoder(width, latent_dim, lr)\n",
    "dm = GlitchDataModule(data=data, width=width)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=epochs, accelerator=\"auto\")\n",
    "trainer.fit(model=ae, datamodule=dm)\n",
    "trainer.save_checkpoint(\"example.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder.load_from_checkpoint(\"example.ckpt\")\n",
    "dm = GlitchDataModule(data='real', width=model.width)\n",
    "trainer = pl.Trainer()\n",
    "trainer.test(datamodule=dm, model=model, ckpt_path=\"example.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "henry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
