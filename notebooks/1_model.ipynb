{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956fff84-b9f4-46f2-a69a-fa0cb528cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.fft import irfft\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd5d72-acf5-4691-9710-25479c6e1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(width: int, latent_dim : int, act_fn : object, encoder = True):\n",
    "    sizes = []\n",
    "    size = width\n",
    "    while size > 30:\n",
    "        sizes.append(int(size))\n",
    "        size = size / 2\n",
    "    sizes.append(latent_dim)\n",
    "\n",
    "    if encoder==False:\n",
    "        sizes = sizes[::-1]\n",
    "    layers = []\n",
    "    for layer_idx in range(len(sizes) - 1):\n",
    "        layers.append(nn.Linear(sizes[layer_idx], sizes[layer_idx+1]))\n",
    "        layers.append(act_fn())\n",
    "    layers.pop()\n",
    "\n",
    "    return layers\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, width: int, latent_dim: int, act_fn: object = nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(*get_layers(width, latent_dim, act_fn))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, width: int, latent_dim: int, act_fn: object = nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(*get_layers(width, latent_dim, act_fn, encoder=False))\n",
    "                                 \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0267c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        width: int,\n",
    "        latent_dim: int,\n",
    "        lr: float,\n",
    "        encoder_class: object = Encoder,\n",
    "        decoder_class: object = Decoder,\n",
    "    ):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = lr\n",
    "        self.width = width\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = encoder_class(width, latent_dim)\n",
    "        self.decoder = decoder_class(width, latent_dim)\n",
    "        self.val_loss = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "\n",
    "    def _get_reconstruction_loss(self, x):\n",
    "        x_hat = self.forward(x)\n",
    "        loss = F.mse_loss(x, x_hat)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.val_loss.append(loss)\n",
    "        self.log(\"val_loss\", loss, sync_dist=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.val_loss).mean()\n",
    "        self.log(\"val_loss\", avg_loss, sync_dist=True)\n",
    "        self.val_loss.clear()\n",
    "\n",
    "    def _test_plot(self, noisy:torch.Tensor, denoised:torch.Tensor, idx:int,\n",
    "                   loss:float):\n",
    "        noisy = noisy.cpu().numpy()\n",
    "        denoised = denoised.cpu().numpy()\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(noisy[idx,:], label='Noisy')\n",
    "        plt.plot(denoised[idx,:], label='Denoised')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xlim([0, self.width-1])\n",
    "        plt.ylabel('Normalized amplitude')\n",
    "        plt.xlabel('index')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(noisy[idx,:] - denoised[idx,:], label='Residual')\n",
    "        plt.legend()\n",
    "        plt.xlim([0, self.width-1])\n",
    "        plt.xlabel('index')\n",
    "        plt.suptitle(f'Loss: {loss:.7f}')\n",
    "        plt.savefig(f'reports/figures/{self.width}_{self.latent_dim}_{idx}.png', dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        x_hat = self.forward(batch)\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        rand = np.random.random(10)*batch.size(dim=0)  # indexes for plotting\n",
    "        for rand_no in rand:\n",
    "            self._test_plot(batch, x_hat, int(rand_no), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetData():\n",
    "    def __init__(\n",
    "        self,\n",
    "        width: int = 128\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.width = width\n",
    "    \n",
    "    def _gen_blip(self, fs:int, flow:int, fhigh:int, dt_shift:float):\n",
    "        freqs = np.arange(1 + fs//2)\n",
    "        spec = np.zeros(len(freqs))\n",
    "        logf = np.log(freqs[flow:fhigh])\n",
    "        spec1 = (logf-logf[0])*(logf[-1]-logf)\n",
    "        spec[flow:fhigh] = spec1/np.max(spec1)\n",
    "        spec_shifted = np.exp(-1j*freqs*2*np.pi*dt_shift)*spec\n",
    "        blip = np.roll(irfft(spec_shifted), fs//2)\n",
    "        return blip / np.max(blip)\n",
    "\n",
    "    def fake_blips(self, fs: int = 512):\n",
    "        dt_shifts = np.random.normal(0, 5, 50) / 1000  # in ms\n",
    "        f_lows = np.linspace(15, 35, 21, dtype=int)\n",
    "        f_highs = np.linspace(190, 230, 41, dtype=int)\n",
    "\n",
    "        blips = []\n",
    "        for dt_shift in dt_shifts:\n",
    "            for f_low in f_lows:\n",
    "                for f_high in f_highs:\n",
    "                    blip = self._gen_blip(fs, f_low, f_high, dt_shift)\n",
    "                    blips.append(blip)\n",
    "        blips = np.array(blips)\n",
    "        blips = blips[:, fs//2-self.width//2:fs//2+self.width//2]\n",
    "        blips = np.array(blips).astype('float32')\n",
    "        return blips\n",
    "\n",
    "    def shift_blips(self, dset : object = np.array): \n",
    "        shift_idxs = range(-5, 6)\n",
    "        shifted_blips = []\n",
    "        for idx in shift_idxs:\n",
    "            shifted_blips.append(np.roll(dset, idx, axis=1))\n",
    "        shifted_blips = np.array(shifted_blips)\n",
    "        shifted_blips = np.vstack(shifted_blips)\n",
    "        return shifted_blips\n",
    "\n",
    "    def real_blips(self, ddir : object = Path('data/external')):\n",
    "        files = ddir.glob('*.npy')\n",
    "        blips = []\n",
    "        for blip in files:\n",
    "            blip_data = np.load(blip)[:,1]\n",
    "            blips.append(blip_data)\n",
    "        blips = np.array(blips)\n",
    "        length = len(blips.T)\n",
    "        blips = blips[:, length//2-self.width//2:length//2+self.width//2]\n",
    "        blips = blips.astype('float32')\n",
    "        return blips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d4d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlitchDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: str = 'real',\n",
    "        batch_size: int = 100,\n",
    "        width: int = 128\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.width = width\n",
    "        self.prepare_data_per_node = False\n",
    "\n",
    "    def prepare_data(self):\n",
    "        gd = GetData(self.width)\n",
    "        if self.data == 'real':\n",
    "            self.glitch = F.normalize(torch.from_numpy(gd.real_blips()))\n",
    "        elif self.data == 'fake':\n",
    "            self.glitch = F.normalize(torch.from_numpy(gd.fake_blips()))\n",
    "        else:\n",
    "            raise SystemExit(\"Works only with 'real' and 'fake' data\")\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.glitch_train, self.glitch_val, self.glitch_test = torch.utils.data.random_split(self.glitch, [0.89, 0.1, 0.01], generator=torch.manual_seed(0))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.data == 'real':\n",
    "            # generate more glitches for training by shifting them\n",
    "            gd = GetData(self.width)\n",
    "            return DataLoader(gd.shift_blips(self.glitch_train), batch_size=self.batch_size, num_workers=4)\n",
    "        else:\n",
    "            return DataLoader(self.glitch_train, batch_size=self.batch_size, num_workers=4)\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.glitch_val, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.glitch_test, batch_size=len(self.glitch_test), num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb31aa86-d0f4-4de1-b1ef-e9f1a641a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'real'\n",
    "width = 128\n",
    "latent_dim = 5\n",
    "lr = 1e-3\n",
    "epochs = 2\n",
    "ae = AutoEncoder(width, latent_dim, lr)\n",
    "dm = GlitchDataModule(data=data, width=width)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=epochs, accelerator=\"auto\")\n",
    "trainer.fit(model=ae, datamodule=dm)\n",
    "trainer.save_checkpoint(\"example.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder.load_from_checkpoint(\"example.ckpt\")\n",
    "dm = GlitchDataModule(data='real', width=model.width)\n",
    "trainer = pl.Trainer()\n",
    "trainer.test(datamodule=dm, model=model, ckpt_path=\"example.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "henry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
