{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956fff84-b9f4-46f2-a69a-fa0cb528cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.fft import irfft\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0cd5d72-acf5-4691-9710-25479c6e1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(width: int, latent_dim : int, act_fn : object, encoder = True):\n",
    "    sizes = []\n",
    "    size = width\n",
    "    while size > 30:\n",
    "        sizes.append(int(size))\n",
    "        size = size / 2\n",
    "    sizes.append(latent_dim)\n",
    "\n",
    "    if encoder==False:\n",
    "        sizes = sizes[::-1]\n",
    "    layers = []\n",
    "    for layer_idx in range(len(sizes) - 1):\n",
    "        layers.append(nn.Linear(sizes[layer_idx], sizes[layer_idx+1]))\n",
    "        layers.append(act_fn())\n",
    "    layers.pop()\n",
    "\n",
    "    return layers\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, width: int, latent_dim: int, act_fn: object = nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(*get_layers(width, latent_dim, act_fn))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, width: int, latent_dim: int, act_fn: object = nn.ReLU):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(*get_layers(width, latent_dim, act_fn, encoder=False))\n",
    "                                 \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0267c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        width: int,\n",
    "        latent_dim: int,\n",
    "        lr: float,\n",
    "        encoder_class: object = Encoder,\n",
    "        decoder_class: object = Decoder,\n",
    "    ):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.lr = lr\n",
    "        self.width = width\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = encoder_class(width, latent_dim)\n",
    "        self.decoder = decoder_class(width, latent_dim)\n",
    "        self.val_loss = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "\n",
    "    def _get_reconstruction_loss(self, x):\n",
    "        x_hat = self.forward(x)\n",
    "        loss = F.mse_loss(x, x_hat)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.val_loss.append(loss)\n",
    "        self.log(\"val_loss\", loss, sync_dist=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.val_loss).mean()\n",
    "        self.log(\"val_loss\", avg_loss, sync_dist=True)\n",
    "        self.val_loss.clear()\n",
    "\n",
    "    def _test_plot(self, noisy:torch.Tensor, denoised:torch.Tensor, idx:int,\n",
    "                   loss:float):\n",
    "        noisy = noisy.cpu().numpy()\n",
    "        denoised = denoised.cpu().numpy()\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(noisy[idx,:], label='Noisy')\n",
    "        plt.plot(denoised[idx,:], label='Denoised')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xlim([0, self.width-1])\n",
    "        plt.ylabel('Normalized amplitude')\n",
    "        plt.xlabel('index')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(noisy[idx,:] - denoised[idx,:], label='Residual')\n",
    "        plt.legend()\n",
    "        plt.xlim([0, self.width-1])\n",
    "        plt.xlabel('index')\n",
    "        plt.suptitle(f'Loss: {loss:.7f}')\n",
    "        plt.savefig(f'plots/{self.width}_{self.latent_dim}_{idx}.png', dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        x_hat = self.forward(batch)\n",
    "        loss = self._get_reconstruction_loss(batch)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        rand = np.random.random(10)*batch.size(dim=0)  # indexes for plotting\n",
    "        for rand_no in rand:\n",
    "            self._test_plot(batch, x_hat, int(rand_no), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3891c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetData():\n",
    "    def __init__(\n",
    "        self,\n",
    "        width: int = 128\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.width = width\n",
    "    \n",
    "    def _gen_blip(self, fs:int, flow:int, fhigh:int, dt_shift:float):\n",
    "        freqs = np.arange(1 + fs//2)\n",
    "        spec = np.zeros(len(freqs))\n",
    "        logf = np.log(freqs[flow:fhigh])\n",
    "        spec1 = (logf-logf[0])*(logf[-1]-logf)\n",
    "        spec[flow:fhigh] = spec1/np.max(spec1)\n",
    "        spec_shifted = np.exp(-1j*freqs*2*np.pi*dt_shift)*spec\n",
    "        blip = np.roll(irfft(spec_shifted), fs//2)\n",
    "        return blip / np.max(blip)\n",
    "\n",
    "    def fake_blips(self, fs: int = 512):\n",
    "        dt_shifts = np.random.normal(0, 5, 50) / 1000  # in ms\n",
    "        f_lows = np.linspace(15, 35, 21, dtype=int)\n",
    "        f_highs = np.linspace(190, 230, 41, dtype=int)\n",
    "\n",
    "        blips = []\n",
    "        for dt_shift in dt_shifts:\n",
    "            for f_low in f_lows:\n",
    "                for f_high in f_highs:\n",
    "                    blip = self._gen_blip(fs, f_low, f_high, dt_shift)\n",
    "                    blips.append(blip)\n",
    "        blips = np.array(blips)\n",
    "        blips = blips[:, fs//2-self.width//2:fs//2+self.width//2]\n",
    "        blips = np.array(blips).astype('float32')\n",
    "        return blips\n",
    "\n",
    "    def shift_blips(self, dset : object = np.array): \n",
    "        shift_idxs = range(-5, 6)\n",
    "        shifted_blips = []\n",
    "        for idx in shift_idxs:\n",
    "            shifted_blips.append(np.roll(dset, idx, axis=1))\n",
    "        shifted_blips = np.array(shifted_blips)\n",
    "        shifted_blips = np.vstack(shifted_blips)\n",
    "        return shifted_blips\n",
    "\n",
    "    def real_blips(self, ddir : object = Path('data/lfblips/')):\n",
    "        files = ddir.glob('*.npy')\n",
    "        blips = []\n",
    "        for blip in files:\n",
    "            blip_data = np.load(blip)[:,1]\n",
    "            blips.append(blip_data)\n",
    "        blips = np.array(blips)\n",
    "        length = len(blips.T)\n",
    "        blips = blips[:, length//2-self.width//2:length//2+self.width//2]\n",
    "        blips = blips.astype('float32')\n",
    "        return blips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16d4d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlitchDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: str = 'real',\n",
    "        batch_size: int = 100,\n",
    "        width: int = 128\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.width = width\n",
    "        self.prepare_data_per_node = False\n",
    "\n",
    "    def prepare_data(self):\n",
    "        gd = GetData(self.width)\n",
    "        if self.data == 'real':\n",
    "            self.glitch = F.normalize(torch.from_numpy(gd.real_blips()))\n",
    "        elif self.data == 'fake':\n",
    "            self.glitch = F.normalize(torch.from_numpy(gd.fake_blips()))\n",
    "        else:\n",
    "            raise SystemExit(\"Works only with 'real' and 'fake' data\")\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.glitch_train, self.glitch_val, self.glitch_test = torch.utils.data.random_split(self.glitch, [0.89, 0.1, 0.01], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.data == 'real':\n",
    "            # generate more glitches for training by shifting them\n",
    "            gd = GetData(self.width)\n",
    "            return DataLoader(gd.shift_blips(self.glitch_train), batch_size=self.batch_size, num_workers=4)\n",
    "        else:\n",
    "            return DataLoader(self.glitch_train, batch_size=self.batch_size, num_workers=4)\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.glitch_val, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.glitch_test, batch_size=len(self.glitch_test), num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb31aa86-d0f4-4de1-b1ef-e9f1a641a9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 10.5 K\n",
      "1 | decoder | Decoder | 10.7 K\n",
      "------------------------------------\n",
      "21.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.2 K    Total params\n",
      "0.085     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2527aef3e94b8f82e13a181135178a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d0580b77e84070bfa3d526bfef845f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8464807f6f2b404a98b58dfe3a74a4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cb9cbffb274c4591229d2bae2d5830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b4cf3fa3294da9abb4802722fab8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc47fe99c7c248e6aeeaeb043bc5f426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4845e21b94664718be4418f53556fe84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27197a6849d742cab8f18c53c0d37ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60f410f4e6743d58e5c126254f3cda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe5927718774970bc227c8f416466e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4090ee0aae9541128e69cf906b227681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5207421ebae44d78acd40dab7719424d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3fb6e95d8e5400da8e30757da03edfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735d3373a7fa479e8031981606a139be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a793483e0d8b4a7b8a5dbed8a3e837bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fff2e87b093944d9819d9b5b9b6fc6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1bde20faa5e4d49a2ae371d2e22a4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b24fbe9d2d14390929b4e6add568417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6b0b112e2b416e80b8e59eb9b27a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa638c4877a4bdc80020b824a6097d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c13510662146ae9763b44a22a401a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61cddecad491419795176ea568e4ae9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "width = 128\n",
    "latent_dim = 6\n",
    "lr = 1e-3\n",
    "ae = AutoEncoder(width, latent_dim, lr)\n",
    "dm = GlitchDataModule(data='real', width=width)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20, accelerator=\"gpu\")\n",
    "trainer.fit(model=ae, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12ffb637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/burlaivis/bin/miniconda3/envs/henry/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:186: .test(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe4e9ec249d40f98b53104f1f9944cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss          0.0017756845336407423\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0017756845336407423}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!rm plots/*\n",
    "trainer.test(ckpt_path='last', datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdedb622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "henry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
